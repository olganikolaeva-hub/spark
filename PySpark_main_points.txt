-----------------------------------------------------------------------------------------------------------------------------------------------------
PySpark (весь препроцессинг должен строиться на спарке)
Как он появился, как он устроен архитектурно, почему он такой, какой он есть.
Рассмотрим 2 структуры данных : rdd и dataframe. Они могут применяться в разных сценариях.
*Для google понадобился инструмент для хранения большого количества индексов.
-----------------------------------------------------------------------------------------------------------------------------------------------------
0. BigData (volume,variety, velosity) - те объемы данных, которые мы не можем обсчитать на одной машине за приемлемое время,
                                     данные неструктурированы, что не позволяет обсчитать их быстро.
                                     про объем  - речь об экзабайтах.
                                     сырые данные идут плотным потоком и их много, нет возможности настроить сильную взаимосвязь между ними,
                                     как это сделано в реляционных базах данных.  
                                     модель хранения данных - горизонтальная - это дешево (в реляционных - вертикальная).                                    

1. BigData - это:
   1. etl\elt продукт, который позволяет работать с большим обьемом неструктурированных данных
   2. технологии обработки больших данных
   3. управление качеством данных
   4. технологии предоставления данных потребителю
   5. немного machine learning как часть etl

2. Экосистема Hadoop - это экосистема, которая позволяет объять все нюансы обработки больших данных.
   Сервисы между собой взаимодействуют, между ними есть коннекторы.
   (ide для разработки) 

3. HDFS (под покровительством Apache) - распределенное файловая система, в которой файлы распределены поблочно по различным узлам.
   Это система, в которой мы не можем перезаписывать файлы, это система, которая заточен под паттерн взаимодействия с данными
   "write once, read many".

4. Структура самого HDFS: Name Node, Data Node. Клиент обращается к Name Node, она отвечает в каком месте лежат данные.
   есть принцип репликации, которая позволяет нам быть устойчивым к падению данных. HDFS - это про жесткие диски.

5. Достоинство: высокая надежность, отказоустройчивость, высокая масштабируемость, низкая стоимость, скорость,
                open source.
   Недостатки: файлы пишутся однократно, нет связей, слабое звено - name node (если она отваливается, все плохо)

6. Map Reduce - это не алгоритм, это парадигма. С помощью map reduce могут быть реализованы алгоритмы.
   например, классическая задача google - подсчет частоты слов в тексте, с этой задачи все и началось.

6. Map Reduce: позволяет обрабатывать данные, лежащие на разных узлах с помощью 3 операций:
   локально на каждой машине считаем  агрегат;
   затем shuffle по значению ключа, разделяем hash на N частей, сортируем, шафлим, перетасовываем;
   reduce - считаем итоговый агрегат;
   Затем все собираем и передаем дальше.
   
   Для чего нужно: Данные могут не влезать на жесткий диск одной машины;
   Низкоуровневый. Логика сложнее джойна нескольких таблиц, а значит это несколько длней разработки.   
   Пайплайн обработки нужно писать руками. Логика - сложная. 

7. Map Reduce работает с диском, а значит он медленне систем, которые работают с оперативной памятью. Но оперативная память дороже,
   но оперативная память дает скорость.

8. Spark - фреймворк с открытым исходным кодом для реализации распределенной обработки неструктурированных или слабоструктурированных
           входящих к экосистему hadoop. Обращаться к движку spark можно с помощью api. Спарк написан на java.

9. Ядро c api На каждой ноде поднимается jvm машина, 

10. У спарка есть ядро, к которому мы обращаемся через api (core and engine).
    У этого ядра есть возможность общаться через нативную скала, реализована возможность писать sql запросы, реализован api python.

11. На каждой ноде подымается jvm машина, на которой крутится спарк, на каждой ноде запускается jvm машина.
    Все запросы, которые мы передаем через api, и крутятся на jvm-машинах.

12. Спарк sql (препроцессинг) - 90% времени мы и работаем с ним (то, что мы делаем в падас),
    Спарк стримминг - для простых запросов может достигать лага в несколько сотен десятков-сотен миллисекунд,
                      микробатчинговая архитектура. 
    ML learning - библиотека в себе содержит стандартные модели (это не sklearn),
    Есть блок для графов.

13. Архитектура приложений на спарке выглядит так:
    - у нас есть hdfs, hbase, cassandra (распределенная файловая система), s3 - облачное файловой хранилище (все началось с amazon)
    - у нас есть ярн - распределитель ресурсов (или kubernets - управление ресурсами,облачное хранение, изоляция, масштабируемость)
    - spark core
    - другие похожие инструменты (hive, impala)
    - hive может работать поверх спарка

14. спарк - 100 раз быстрее в памяти и в 10 раз выстрее на диске

15. map reduce - линейная обработка данных, spark - итеративная обработка, аналитика в режиме реального времени, обработка графов, машинное обучение.
    map reduce - две операции для всех действий, spark - высокоуровневое api.
    map reduce - нет, spark - кэширование.
    в спарк есть инструмент, который оптимизирует запросы.
    есть партицирование.

16. структура спарка напоминает hdfs: есть worker ноды, есть cluster manager - какие задачи, какие таски будут идти на воркерноды.

17. код разбивается на таски, на граф операций, ацикличный направленный граф, (код разбивается на другое представление)
    которые выполняются распределенно. все последующие задачи будуь ждать, пока worker ноды освободятся. 

18. В executere есть память для кэша, есть память для тасков.

19. Точка входа в приложение - spark session, это объект - это наше api, с помощью чего мы выполняем все запросы и команды.
  
20. Форматы файлов данных:
    - текстовы форматы (txt, csv, json) - человекочитаемые
    - бинарный формат (parquet (колончатый формат), auro) - сжатие, оптимизация хранения на диске

                                                                                   